# The LLM Development Stack

This is the official GitHub repository for the Pearson Live Training course **“The LLM Development Stack”**, created by Rob Barton and Jerome Henry.

This course introduces developers and engineers to the complete modern LLM development stack, covering foundational tools, local model-serving platforms, agentic frameworks and protocols, cloud-based deployment, and evaluation/benchmarking—all delivered through practical demos, code labs, and live Q&A.

---

## Authors

| Name            | Role                            |
|-----------------|---------------------------------|
| Rob Barton      | Cisco Distinguished AI Engineer |
| Jerome Henry    | Cisco Distinguished Engineer    |

---

## Course Outline

### Section 1: LLM Development Foundational Tools

This section is a combination of demo and slides, introducing the environments and platforms used throughout the course.

- Google Colab  
- Hugging Face  
- Q&A

---

### Section 2: LLM Management Platforms

Learn how to run LLMs locally using modern tools for inference and UI.

- Overview of Ollama and LMStudio  
- Ollama deep dive  
- Developing GenAI apps using Ollama and Open WebUI  
- Q&A

---

### Section 3: Agentic AI Development Tools

Build intelligent AI agents using Python and agentic development frameworks.

- Agentic frameworks: LangChain/LangGraph, CrewAI, AutoGen  
- Automating agents with LangChain  
- Programming your own agent with Python  
- Q&A

---

### Section 4: Agentic AI Development Protocols

Explore how agents interact and share context using cutting-edge protocols.

- Agentic Protocols  
- Message Chain Protocol (MCP)  
- Agent to Agent (A2A)  
- Model Context Protocol (MCP)  
- Q&A

---

### Section 5: Cloud-based LLM Development Platforms

Deploy and scale your AI applications using cloud-based LLM tools.

- Overview of Cloud LLM development tools (Google Vertex, Azure AI Studio, AWS Bedrock)  
- AWS Bedrock deep dive  
- Building an AI Assistant to use Bedrock  
- Q&A

---

### Section 6: LLM Monitoring and Observability

Learn how to monitor and observe LLM-based applications.

- Overview of LLM monitoring and observability  
- An introduction to LangSmith  
- Q&A

---

## Prerequisites

To make the most of this course, you should have:

- Basic Python programming experience  
- Familiarity with AI/ML concepts  
- A GitHub account and the ability to use browser-based coding tools (e.g., Google Colab)

---

## Repository Structure

The repository is organized into sections that correspond to the course modules, with additional supporting files:

### Course Sections

- `Lesson-1-Foundational-Tools/` – Includes Google Colab and Hugging Face demos to introduce the development environment  
- `Lesson-2-LLM-Management-Platforms/` – Resources and examples using Ollama, LM Studio, and Open WebUI  
- `Lesson-3-Agentic-Development-Tools/` – Agentic AI frameworks like LangChain, LangGraph, CrewAI, and AutoGen  
- `Lesson-4-Agentic-Protocols/` – Covers Message Chain Protocol (MCP), Agent-to-Agent (A2A), and Model Context Protocol  
- `Lesson-5-Cloud-LLM-Platforms/` – Hands-on projects using AWS Bedrock, Google Vertex, and Azure AI Studio  
- `Lesson-6-LLM-Monitoring and Observability/` – An introduction to LangSmith 

### Supporting Files

- `requirements.txt` – Lists all Python package dependencies  
- `.gitignore` – Specifies files and directories to be ignored by Git  

Each section directory typically contains:

- Python scripts (`.py`) and Jupyter notebooks (`.ipynb`) with working examples  
- Data files used in the examples (where applicable)  
- README files with section-specific instructions  
- Visualizations and demos  
- Additional explanatory materials  

> **Note:** Some sections may be added or updated as the course progresses.

---

## Getting Started

1. Clone this repository to your local machine:

   `git clone https://github.com/robbarto2/Oreilly-LLM-Development-Stack.git`

2. Navigate to the project directory:

   `cd Oreilly-LLM-Development-Stack`

3. Install dependencies:

   `pip install -r requirements.txt`

4. Open any of the demo notebooks in Google Colab or your preferred IDE.

5. (Optional) For local development, install tools like Ollama and LM Studio.

---

This repository will be updated regularly as the course progresses.
